{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://neo4j.com/developer/graph-data-science/build-knowledge-graph-nlp-ontologies/\n",
    "\n",
    "Facts\n",
    "    Instance data. This would include graph data imported from any data source and could be structured (e.g. JSON/XML) or semi structured (e.g. HTML)\n",
    "\n",
    "Explicit Knowledge\n",
    "    Explicit description of how instance data relates. This comes from ontologies, taxonomies, or any kind of metadata definition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "# Set up ENV\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD_\")\n",
    "database = \"neo4j\"\n",
    "google_nlp_key = os.getenv(\"GOOGLE_NLP\")\n",
    "\n",
    "graph = Graph(url, auth=(username, password), name=database)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set-up\n",
    "queries = [\n",
    "    \"CREATE CONSTRAINT n10s_unique_uri FOR (r:Resource) REQUIRE r.uri IS UNIQUE;\",\n",
    "    'CALL n10s.graphconfig.init({handleVocabUris: \"MAP\"});',\n",
    "    \"call n10s.nsprefixes.add('neo','neo4j://voc#');\",\n",
    "    'CALL n10s.mapping.add(\"neo4j://voc#subCatOf\",\"SUB_CAT_OF\");',\n",
    "    'CALL n10s.mapping.add(\"neo4j://voc#about\",\"ABOUT\");'\n",
    "]\n",
    "\n",
    "# for q in queries:\n",
    "#     graph.run(q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://query.wikidata.org/\n",
    "\n",
    "# Software systems taxonomy\n",
    "query = \"\"\"\n",
    "WITH \"https://query.wikidata.org/sparql?query=prefix%20neo%3A%20%3Cneo4j%3A%2F%2Fvoc%23%3E%20%0A%23Cats%0A%23SELECT%20%3Fitem%20%3Flabel%20%0ACONSTRUCT%20%7B%0A%3Fitem%20a%20neo%3ACategory%20%3B%20neo%3AsubCatOf%20%3FparentItem%20.%20%20%0A%20%20%3Fitem%20neo%3Aname%20%3Flabel%20.%0A%20%20%3FparentItem%20a%20neo%3ACategory%3B%20neo%3Aname%20%3FparentLabel%20.%0A%20%20%3Farticle%20a%20neo%3AWikipediaPage%3B%20neo%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%0A%7D%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20(wdt%3AP31%7Cwdt%3AP279)*%20wd%3AQ2429814%20.%0A%20%20%3Fitem%20wdt%3AP31%7Cwdt%3AP279%20%3FparentItem%20.%0A%20%20%3Fitem%20rdfs%3Alabel%20%3Flabel%20.%0A%20%20filter(lang(%3Flabel)%20%3D%20%22en%22)%0A%20%20%3FparentItem%20rdfs%3Alabel%20%3FparentLabel%20.%0A%20%20filter(lang(%3FparentLabel)%20%3D%20%22en%22)%0A%20%20%0A%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Farticle%20schema%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AinLanguage%20%22en%22%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AisPartOf%20%3Chttps%3A%2F%2Fen.wikipedia.org%2F%3E%20.%0A%20%20%20%20%7D%0A%20%20%0A%7D\" AS softwareSystemsUri\n",
    "CALL n10s.rdf.import.fetch(softwareSystemsUri, 'Turtle' , { headerParams: { Accept: \"application/x-turtle\" } })\n",
    "YIELD terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams\n",
    "RETURN terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Programming languages taxonomy\n",
    "query = \"\"\"\n",
    "WITH \"https://query.wikidata.org/sparql?query=prefix%20neo%3A%20%3Cneo4j%3A%2F%2Fvoc%23%3E%20%0A%23Cats%0A%23SELECT%20%3Fitem%20%3Flabel%20%0ACONSTRUCT%20%7B%0A%3Fitem%20a%20neo%3ACategory%20%3B%20neo%3AsubCatOf%20%3FparentItem%20.%20%20%0A%20%20%3Fitem%20neo%3Aname%20%3Flabel%20.%0A%20%20%3FparentItem%20a%20neo%3ACategory%3B%20neo%3Aname%20%3FparentLabel%20.%0A%20%20%3Farticle%20a%20neo%3AWikipediaPage%3B%20neo%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%0A%7D%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20(wdt%3AP31%7Cwdt%3AP279)*%20wd%3AQ9143%20.%0A%20%20%3Fitem%20wdt%3AP31%7Cwdt%3AP279%20%3FparentItem%20.%0A%20%20%3Fitem%20rdfs%3Alabel%20%3Flabel%20.%0A%20%20filter(lang(%3Flabel)%20%3D%20%22en%22)%0A%20%20%3FparentItem%20rdfs%3Alabel%20%3FparentLabel%20.%0A%20%20filter(lang(%3FparentLabel)%20%3D%20%22en%22)%0A%20%20%0A%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Farticle%20schema%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AinLanguage%20%22en%22%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AisPartOf%20%3Chttps%3A%2F%2Fen.wikipedia.org%2F%3E%20.%0A%20%20%20%20%7D%0A%20%20%0A%7D\" AS programmingLanguagesUri\n",
    "CALL n10s.rdf.import.fetch(programmingLanguagesUri, 'Turtle' , { headerParams: { Accept: \"application/x-turtle\" } })\n",
    "YIELD terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams\n",
    "RETURN terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data formats taxonomy\n",
    "query = \"\"\"\n",
    "WITH \"https://query.wikidata.org/sparql?query=prefix%20neo%3A%20%3Cneo4j%3A%2F%2Fvoc%23%3E%20%0A%23Cats%0A%23SELECT%20%3Fitem%20%3Flabel%20%0ACONSTRUCT%20%7B%0A%3Fitem%20a%20neo%3ACategory%20%3B%20neo%3AsubCatOf%20%3FparentItem%20.%20%20%0A%20%20%3Fitem%20neo%3Aname%20%3Flabel%20.%0A%20%20%3FparentItem%20a%20neo%3ACategory%3B%20neo%3Aname%20%3FparentLabel%20.%0A%20%20%3Farticle%20a%20neo%3AWikipediaPage%3B%20neo%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%0A%7D%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20(wdt%3AP31%7Cwdt%3AP279)*%20wd%3AQ24451526%20.%0A%20%20%3Fitem%20wdt%3AP31%7Cwdt%3AP279%20%3FparentItem%20.%0A%20%20%3Fitem%20rdfs%3Alabel%20%3Flabel%20.%0A%20%20filter(lang(%3Flabel)%20%3D%20%22en%22)%0A%20%20%3FparentItem%20rdfs%3Alabel%20%3FparentLabel%20.%0A%20%20filter(lang(%3FparentLabel)%20%3D%20%22en%22)%0A%20%20%0A%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Farticle%20schema%3Aabout%20%3Fitem%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AinLanguage%20%22en%22%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20schema%3AisPartOf%20%3Chttps%3A%2F%2Fen.wikipedia.org%2F%3E%20.%0A%20%20%20%20%7D%0A%20%20%0A%7D\" AS dataFormatsUri\n",
    "CALL n10s.rdf.import.fetch(dataFormatsUri, 'Turtle' , { headerParams: { Accept: \"application/x-turtle\" } })\n",
    "YIELD terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams\n",
    "RETURN terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CALL apoc.meta.stats()\n",
    "YIELD labels, relTypes, relTypesCount\n",
    "RETURN labels, relTypes, relTypesCount;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Weâ€™re going to import some articles from dev.to into Neo4j. articles.csv contains a list of 30 articles of interest.\n",
    "query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'https://github.com/neo4j-examples/nlp-knowledge-graph/raw/master/import/articles.csv' AS row\n",
    "RETURN row\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a query to get the names of categories that are parents\n",
    "# match (c:Category)<-[:SUB_CAT_OF*]-() return distinct c.name\n",
    "\n",
    "# Create node with Article label and uri property if it dosen't already exist\n",
    "# Scrape data from the URI using the provided CSS selectors\n",
    "# Post processing of the values returned from scrapping the URI\n",
    "# Update node with body, title, and datetime properties\n",
    "\n",
    "# Has to install extended https://neo4j.com/labs/apoc/5/installation/\n",
    "# https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases/5.3.1\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "  \"LOAD CSV WITH HEADERS FROM 'https://github.com/neo4j-examples/nlp-knowledge-graph/raw/master/import/articles.csv' AS row\n",
    "   RETURN row\",\n",
    "  \"MERGE (a:Article {uri: row.uri})\n",
    "   WITH a\n",
    "   CALL apoc.load.html(a.uri, {\n",
    "     body: 'body div.spec__body p',\n",
    "     title: 'h1',\n",
    "     time: 'time'\n",
    "   })\n",
    "   YIELD value\n",
    "   UNWIND value.body AS item\n",
    "   WITH a,\n",
    "        apoc.text.join(collect(item.text), '') AS body,\n",
    "        value.title[0].text AS title,\n",
    "        value.time[0].attributes.datetime AS date\n",
    "   SET a.body = body , a.title = title, a.datetime = datetime(date)\",\n",
    "  {batchSize: 5, parallel: true}\n",
    ")\n",
    "YIELD batches, total, timeTaken, committedOperations\n",
    "RETURN batches, total, timeTaken, committedOperations;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using https://cloud.google.com/natural-language\n",
    "# \":params key => (\"<insert-key-here>\")\"\n",
    "\n",
    "# 1 node is the article and value contains the extracted entities\n",
    "# 2 Only include entities that have a Wikipedia URL\n",
    "# 3 Find a node that matches the Wikipedia URL. Create one if it doesnâ€™t already exist.\n",
    "# 4 Create a HAS_ENTITY relationship between the Article node and WikipediaPage\n",
    "\n",
    "# set_key = f\":params key => ('{google_nlp_key}')\"\n",
    "\n",
    "# Each row contains a name property that describes the entity. salience is an indicator of the importance or centrality of that entity to the entire document text.\n",
    "#\n",
    "# Some entities also contain a Wikipedia URL, which is found via the metadata.wikipedia_url key.\n",
    "# The first entity, RethinkDB, is the only entity in this list that has such a URL. \n",
    "# Weâ€™re going to filter the rows returned to only include ones that have a Wikipedia URL and weâ€™ll then connect the Article nodes to the WikipediaPage nodes that have that URL.\n",
    "query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "  \"MATCH (a:Article)\n",
    "   WHERE a.processed is NULL\n",
    "   RETURN a\",\n",
    "  \"CALL apoc.nlp.gcp.entities.stream([item in $_batch | item.a], {\n",
    "     nodeProperty: 'body',\n",
    "     key: $key\n",
    "   })\n",
    "   YIELD node, value\n",
    "   SET node.processed = true\n",
    "   WITH node, value\n",
    "   UNWIND value.entities AS entity\n",
    "   WITH entity, node\n",
    "   WHERE not(entity.metadata.wikipedia_url is null)\n",
    "   MERGE (page:Resource {uri: entity.metadata.wikipedia_url})\n",
    "   SET page:WikipediaPage\n",
    "   MERGE (node)-[:HAS_ENTITY]->(page)\",\n",
    "  {batchMode: \"BATCH_SINGLE\", batchSize: 10, params: {key: $key}})\n",
    "YIELD batches, total, timeTaken, committedOperations\n",
    "RETURN batches, total, timeTaken, committedOperations;\n",
    "\"\"\"\n",
    "graph.run(query, parameters={\"key\": google_nlp_key})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The n10s.inference.nodesInCategory procedure lets us search from a top level category, finding all its transitive sub categories,\n",
    "# and then returns nodes attached to any of those categories.\n",
    "query = \"\"\"\n",
    "MATCH (c:Category {name: \"NoSQL database management system\"})\n",
    "CALL n10s.inference.nodesInCategory(c, {\n",
    "  inCatRel: \"ABOUT\",\n",
    "  subCatRel: \"SUB_CAT_OF\"\n",
    "})\n",
    "YIELD node\n",
    "MATCH (node)<-[:HAS_ENTITY]-(article)\n",
    "RETURN article.uri AS uri, article.title AS title, article.datetime AS date,\n",
    "       collect(n10s.rdf.getIRILocalName(node.uri))  as explicitTopics\n",
    "ORDER BY date DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "graph.run(query).to_data_frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We can also use the category taxonomy in our query.\n",
    "# We can find articles that share a common parent category by writing the following query\n",
    "query = \"\"\"\n",
    "MATCH (a:Article {uri: \"https://dev.to/qainsights/performance-testing-neo4j-database-using-bolt-protocol-in-apache-jmeter-1oa9\"}),\n",
    "      entityPath = (a)-[:HAS_ENTITY]->(wiki)-[:ABOUT]->(cat),\n",
    "      path = (cat)-[:SUB_CAT_OF]->(parent)<-[:SUB_CAT_OF]-(otherCat),\n",
    "      otherEntityPath = (otherCat)<-[:ABOUT]-(otherWiki)<-[:HAS_ENTITY]-(other)\n",
    "RETURN other.title, other.uri,\n",
    "       [(other)-[:HAS_ENTITY]->()-[:ABOUT]->(entity) | entity.name] AS otherCategories,\n",
    "       collect([node in nodes(path) | node.name]) AS pathToOther;\n",
    "\"\"\"\n",
    "graph.run(query).to_data_frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# contains an ontology for the GRANDstack, MEAN Stack, and LAMP Stack. Before we import this ontology, letâ€™s setup some mappings in n10s:\n",
    "query = \"\"\"\n",
    "CALL n10s.nsprefixes.add('owl','http://www.w3.org/2002/07/owl#');\n",
    "CALL n10s.nsprefixes.add('rdfs','http://www.w3.org/2000/01/rdf-schema#');\n",
    "CALL n10s.mapping.add(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\",\"SUB_CAT_OF\");\n",
    "CALL n10s.mapping.add(\"http://www.w3.org/2000/01/rdf-schema#label\",\"name\");\n",
    "CALL n10s.mapping.add(\"http://www.w3.org/2002/07/owl#Class\",\"Category\");\n",
    "\"\"\"\n",
    "\n",
    "# Software Stacks Ontology\n",
    "query = \"\"\"\n",
    "CALL n10s.rdf.import.fetch(\"http://www.nsmntx.org/2020/08/swStacks\",\"Turtle\")\n",
    "YIELD terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams\n",
    "RETURN terminationStatus, triplesLoaded, triplesParsed, namespaces, callParams;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Google NLP\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Article {uri: \"https://dev.to/lirantal/securing-a-nodejs--rethinkdb--tls-setup-on-docker-containers\"})\n",
    "CALL apoc.nlp.gcp.entities.stream(a, {\n",
    " nodeProperty: 'body',\n",
    " key: $key\n",
    "})\n",
    "YIELD node, value\n",
    "RETURN node, value\n",
    "\"\"\"\n",
    "df = graph.run(query, parameters={'key': google_nlp_key}).to_data_frame()\n",
    "df.to_csv(\"../data/apoc_nlp_gcp_entities_stream.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T23:04:13.962822400Z",
     "start_time": "2023-06-03T23:04:13.707831900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T23:04:14.156826500Z",
     "start_time": "2023-06-03T23:04:14.123829800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
