{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Suppose that you would like to implement a tool that supports message writing, suggesting the next word while you are typing. Moreover, suppose that you would like the tool to learn from you or from a specific set of documents. Such a tool could be useful not only for providing message-writing assistance, but also for supporting spell checking, extracting common phrases, summarizing, and so on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "# Connect to database\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "database = \"masc\"\n",
    "\n",
    "graph = Graph(url, auth=(username, password), name=database)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_constraint = \"CREATE CONSTRAINT FOR (w:Word) REQUIRE w.value IS UNIQUE;\"\n",
    "graph.run(add_constraint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# doesn't work here use desktop\n",
    "load_data_1 = \"\"\"\n",
    "LOAD CSV FROM \"file:///masc_sentences.tsv\" AS line FIELDTERMINATOR '\\t'\n",
    "CALL {\n",
    "    WITH line\n",
    "    WITH line[6] as sentence\n",
    "    WITH split(sentence, \" \") as words\n",
    "    FOREACH ( idx IN range(0,size(words)-2) |\n",
    "    MERGE (w1:Word {value:apoc.text.clean(words[idx])})\n",
    "    MERGE (w2:Word {value:apoc.text.clean(words[idx+1])})\n",
    "    MERGE (w1)-[r:NEXT]->(w2)\n",
    "      ON CREATE SET r.weight = 1\n",
    "      ON MATCH SET r.weight = r.weight + 1)\n",
    "} IN TRANSACTIONS OF 500 ROWS\n",
    "\"\"\"\n",
    "# without cleaning\n",
    "# Added 170037 labels, created 170037 nodes, set 2553105 properties, created 929137 relationships, completed after 261495 ms.\n",
    "# with cleaning\n",
    "# Added 97209 labels, created 97209 nodes, set 2480277 properties, created 806397 relationships, completed after 229257 ms.\n",
    "\n",
    "\n",
    "# New importing query that uses the sentence identifier\n",
    "# The word nodes are unique, so if you have millions of sentences, this schema will create supernodesâ€”that is,\n",
    "# nodes with millions of relationships coming in, going out, or both.\n",
    "load_data = \"\"\"\n",
    "LOAD CSV FROM \"file:///masc_sentences.tsv\" AS line FIELDTERMINATOR '\\t'\n",
    "CALL {\n",
    "    WITH line\n",
    "    WITH line[6] as sentence, line[2] as sentenceId\n",
    "    WITH split(sentence,\" \") as words, sentenceId\n",
    "    FOREACH ( idx IN range(0,size(words)-2) |\n",
    "    MERGE (w1:Word {value:apoc.text.clean(words[idx])})\n",
    "    MERGE (w2:Word {value:apoc.text.clean(words[idx+1])})\n",
    "    CREATE (w1)-[r:NEXT {sentence: sentenceId}]->(w2))\n",
    "} IN TRANSACTIONS OF 500 ROWS\n",
    "\"\"\"\n",
    "# Added 97209 labels, created 97209 nodes, set 2480277 properties, created 2383068 relationships, completed after 93746 ms.\n",
    "delete = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "\"MATCH (p:Word) RETURN p\",\n",
    "\"DETACH DELETE p\", {batchSize:500})\n",
    "\"\"\"\n",
    "# Had to add masc_sentences.tsv to the DB server\n",
    "graph.run(load_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (w:Word {value: \"how\"})-[e:NEXT]->(w2:Word)\n",
    "RETURN w2.value as next, e.weight as frequency\n",
    "ORDER BY frequency desc\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "res = graph.run(query).to_data_frame()\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (w:Word)-[e:NEXT]->(w2:Word)\n",
    "RETURN apoc.text.clean(w2.value) as next, e.weight as frequency\n",
    "ORDER BY frequency desc\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "res = graph.run(query).to_data_frame()\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sentence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (w2:Word {value: \"know\"})-[r:NEXT]->(w3:Word {value: \"how\"})-[e:NEXT]-> (w4:Word)\n",
    "WHERE r.sentence = e.sentence\n",
    "RETURN w4.value as next, count(DISTINCT r) as frequency\n",
    "ORDER BY frequency desc\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "MATCH (w1:Word {value: \"you\"})-[a:NEXT]->(w2:Word {value: \"know\"})-[r:NEXT]->(w3:Word {value: \"how\"})-[e:NEXT]->(w4:Word)\n",
    "WHERE a.sentence = r.sentence AND r.sentence = e.sentence\n",
    "RETURN w4.value as next, count(DISTINCT r) as frequency\n",
    "ORDER BY frequency desc\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "res = graph.run(query).to_data_frame()\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simple Spacy Example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Sentence  1 -----------\n",
      "0 - Marie - Marie - NNP\n",
      "6 - Curie - Curie - NNP\n",
      "12 - received - receive - VBD\n",
      "21 - the - the - DT\n",
      "25 - Nobel - Nobel - NNP\n",
      "31 - Prize - Prize - NNP\n",
      "37 - in - in - IN\n",
      "40 - Physic - Physic - NNP\n",
      "47 - in - in - IN\n",
      "50 - 1903 - 1903 - CD\n",
      "54 - . - . - .\n",
      "-------- Sentence  2 -----------\n",
      "56 - She - she - PRP\n",
      "60 - became - become - VBD\n",
      "67 - the - the - DT\n",
      "71 - first - first - JJ\n",
      "77 - woman - woman - NN\n",
      "83 - to - to - TO\n",
      "86 - win - win - VB\n",
      "90 - the - the - DT\n",
      "94 - prize - prize - NN\n",
      "99 - . - . - .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    i = 1\n",
    "    for sentence in doc.sents:\n",
    "        print(\"-------- Sentence \", i, \"-----------\")\n",
    "        i += 1\n",
    "        for token in sentence:\n",
    "            print(token.idx, \"-\", token.text, \"-\", token.lemma_, \"-\", token.tag_)\n",
    "\n",
    "\n",
    "sentence = \"Marie Curie received the Nobel Prize in Physic in 1903. She became the first woman to win the prize.\"\n",
    "tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T23:20:12.597871200Z",
     "start_time": "2023-05-16T23:19:48.829726300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
